{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e57e2bd-b288-41b8-bcfe-13299ceb11a4",
   "metadata": {},
   "source": [
    "# Initial Exploration - Optimisation\n",
    "#### We got a prediction of around 68% last round. Lets see if I can improve it. Also, need to check why cuda isn't working :(\n",
    "I primarily followed the tutorials here: https://pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f7b16c4-79af-44f6-9fff-64fd5664e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb378c6-0608-443d-864a-b2f3c214ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f456aa64-5455-4370-9124-7d43b75986b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf50384a-a174-494e-a95c-578ef2fe47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"__local/data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"__local/data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d4fbaf-c49f-4cae-b78c-c684f842e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f6ff55-a9da-4d6c-a990-3fbfca9b5ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4f5fef-c0cb-408d-9815-aa331dd8b26a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.291070  [   64/60000]\n",
      "loss: 2.292632  [ 6464/60000]\n",
      "loss: 2.266061  [12864/60000]\n",
      "loss: 2.261965  [19264/60000]\n",
      "loss: 2.230645  [25664/60000]\n",
      "loss: 2.235674  [32064/60000]\n",
      "loss: 2.218832  [38464/60000]\n",
      "loss: 2.208920  [44864/60000]\n",
      "loss: 2.195314  [51264/60000]\n",
      "loss: 2.161665  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 2.159155 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.161879  [   64/60000]\n",
      "loss: 2.140717  [ 6464/60000]\n",
      "loss: 2.117254  [12864/60000]\n",
      "loss: 2.109739  [19264/60000]\n",
      "loss: 2.036493  [25664/60000]\n",
      "loss: 2.044000  [32064/60000]\n",
      "loss: 2.038944  [38464/60000]\n",
      "loss: 1.989239  [44864/60000]\n",
      "loss: 1.968734  [51264/60000]\n",
      "loss: 1.909194  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.893681 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.885677  [   64/60000]\n",
      "loss: 1.876062  [ 6464/60000]\n",
      "loss: 1.811948  [12864/60000]\n",
      "loss: 1.733227  [19264/60000]\n",
      "loss: 1.767694  [25664/60000]\n",
      "loss: 1.708964  [32064/60000]\n",
      "loss: 1.600642  [38464/60000]\n",
      "loss: 1.584186  [44864/60000]\n",
      "loss: 1.566906  [51264/60000]\n",
      "loss: 1.455836  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.511928 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.503184  [   64/60000]\n",
      "loss: 1.492234  [ 6464/60000]\n",
      "loss: 1.469555  [12864/60000]\n",
      "loss: 1.353908  [19264/60000]\n",
      "loss: 1.350065  [25664/60000]\n",
      "loss: 1.269169  [32064/60000]\n",
      "loss: 1.325826  [38464/60000]\n",
      "loss: 1.298884  [44864/60000]\n",
      "loss: 1.284263  [51264/60000]\n",
      "loss: 1.245170  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.239958 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.182994  [   64/60000]\n",
      "loss: 1.283259  [ 6464/60000]\n",
      "loss: 1.164937  [12864/60000]\n",
      "loss: 1.094662  [19264/60000]\n",
      "loss: 1.136640  [25664/60000]\n",
      "loss: 1.097504  [32064/60000]\n",
      "loss: 1.123514  [38464/60000]\n",
      "loss: 1.278558  [44864/60000]\n",
      "loss: 1.108266  [51264/60000]\n",
      "loss: 1.185243  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.075570 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.130218  [   64/60000]\n",
      "loss: 1.050201  [ 6464/60000]\n",
      "loss: 1.116402  [12864/60000]\n",
      "loss: 1.070946  [19264/60000]\n",
      "loss: 1.153189  [25664/60000]\n",
      "loss: 1.119852  [32064/60000]\n",
      "loss: 0.997672  [38464/60000]\n",
      "loss: 0.996402  [44864/60000]\n",
      "loss: 1.058576  [51264/60000]\n",
      "loss: 0.907868  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.972675 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.983636  [   64/60000]\n",
      "loss: 0.935125  [ 6464/60000]\n",
      "loss: 1.018519  [12864/60000]\n",
      "loss: 1.008105  [19264/60000]\n",
      "loss: 0.877686  [25664/60000]\n",
      "loss: 0.968825  [32064/60000]\n",
      "loss: 0.925547  [38464/60000]\n",
      "loss: 1.054941  [44864/60000]\n",
      "loss: 0.985858  [51264/60000]\n",
      "loss: 0.901279  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.903536 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.899770  [   64/60000]\n",
      "loss: 0.863333  [ 6464/60000]\n",
      "loss: 0.880770  [12864/60000]\n",
      "loss: 0.825964  [19264/60000]\n",
      "loss: 0.926347  [25664/60000]\n",
      "loss: 0.932252  [32064/60000]\n",
      "loss: 0.780756  [38464/60000]\n",
      "loss: 0.837405  [44864/60000]\n",
      "loss: 0.823428  [51264/60000]\n",
      "loss: 0.838237  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.852860 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.882828  [   64/60000]\n",
      "loss: 0.723860  [ 6464/60000]\n",
      "loss: 0.861442  [12864/60000]\n",
      "loss: 0.764737  [19264/60000]\n",
      "loss: 0.843426  [25664/60000]\n",
      "loss: 0.670292  [32064/60000]\n",
      "loss: 0.777413  [38464/60000]\n",
      "loss: 0.689997  [44864/60000]\n",
      "loss: 0.702002  [51264/60000]\n",
      "loss: 0.734828  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.814640 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.736570  [   64/60000]\n",
      "loss: 0.856389  [ 6464/60000]\n",
      "loss: 0.839924  [12864/60000]\n",
      "loss: 0.718445  [19264/60000]\n",
      "loss: 0.819039  [25664/60000]\n",
      "loss: 0.618060  [32064/60000]\n",
      "loss: 0.718909  [38464/60000]\n",
      "loss: 0.972854  [44864/60000]\n",
      "loss: 0.751551  [51264/60000]\n",
      "loss: 0.695228  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.785237 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922a67fb-61f4-4bcf-beba-e7ab978fd48d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.311948  [   64/60000]\n",
      "loss: 2.294716  [ 6464/60000]\n",
      "loss: 2.286390  [12864/60000]\n",
      "loss: 2.255832  [19264/60000]\n",
      "loss: 2.257847  [25664/60000]\n",
      "loss: 2.229899  [32064/60000]\n",
      "loss: 2.219047  [38464/60000]\n",
      "loss: 2.211419  [44864/60000]\n",
      "loss: 2.175901  [51264/60000]\n",
      "loss: 2.157623  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 34.4%, Avg loss: 2.150683 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.146438  [   64/60000]\n",
      "loss: 2.125218  [ 6464/60000]\n",
      "loss: 2.085717  [12864/60000]\n",
      "loss: 2.073854  [19264/60000]\n",
      "loss: 2.057316  [25664/60000]\n",
      "loss: 2.020513  [32064/60000]\n",
      "loss: 1.994612  [38464/60000]\n",
      "loss: 1.940949  [44864/60000]\n",
      "loss: 1.884192  [51264/60000]\n",
      "loss: 1.866383  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.869743 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.881047  [   64/60000]\n",
      "loss: 1.880343  [ 6464/60000]\n",
      "loss: 1.779090  [12864/60000]\n",
      "loss: 1.742642  [19264/60000]\n",
      "loss: 1.674071  [25664/60000]\n",
      "loss: 1.577663  [32064/60000]\n",
      "loss: 1.606106  [38464/60000]\n",
      "loss: 1.689183  [44864/60000]\n",
      "loss: 1.565863  [51264/60000]\n",
      "loss: 1.518603  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.501781 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.467152  [   64/60000]\n",
      "loss: 1.445110  [ 6464/60000]\n",
      "loss: 1.324981  [12864/60000]\n",
      "loss: 1.382583  [19264/60000]\n",
      "loss: 1.399707  [25664/60000]\n",
      "loss: 1.303444  [32064/60000]\n",
      "loss: 1.357583  [38464/60000]\n",
      "loss: 1.191124  [44864/60000]\n",
      "loss: 1.318458  [51264/60000]\n",
      "loss: 1.273122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.241138 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.223400  [   64/60000]\n",
      "loss: 1.223842  [ 6464/60000]\n",
      "loss: 1.373681  [12864/60000]\n",
      "loss: 1.132422  [19264/60000]\n",
      "loss: 1.085151  [25664/60000]\n",
      "loss: 1.043226  [32064/60000]\n",
      "loss: 1.042845  [38464/60000]\n",
      "loss: 1.113134  [44864/60000]\n",
      "loss: 0.986304  [51264/60000]\n",
      "loss: 1.092107  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.080073 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.896743  [   64/60000]\n",
      "loss: 0.994978  [ 6464/60000]\n",
      "loss: 0.914898  [12864/60000]\n",
      "loss: 0.970825  [19264/60000]\n",
      "loss: 1.048314  [25664/60000]\n",
      "loss: 1.016375  [32064/60000]\n",
      "loss: 0.991832  [38464/60000]\n",
      "loss: 1.044223  [44864/60000]\n",
      "loss: 0.923654  [51264/60000]\n",
      "loss: 0.955722  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.976237 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.001054  [   64/60000]\n",
      "loss: 1.074640  [ 6464/60000]\n",
      "loss: 0.935824  [12864/60000]\n",
      "loss: 0.960090  [19264/60000]\n",
      "loss: 0.870019  [25664/60000]\n",
      "loss: 0.799556  [32064/60000]\n",
      "loss: 0.855921  [38464/60000]\n",
      "loss: 0.975865  [44864/60000]\n",
      "loss: 0.883108  [51264/60000]\n",
      "loss: 0.895214  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.905193 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.902140  [   64/60000]\n",
      "loss: 0.949846  [ 6464/60000]\n",
      "loss: 0.940915  [12864/60000]\n",
      "loss: 0.765602  [19264/60000]\n",
      "loss: 0.857342  [25664/60000]\n",
      "loss: 0.890589  [32064/60000]\n",
      "loss: 0.780639  [38464/60000]\n",
      "loss: 0.889754  [44864/60000]\n",
      "loss: 0.779877  [51264/60000]\n",
      "loss: 0.823563  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.853038 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.822142  [   64/60000]\n",
      "loss: 0.722265  [ 6464/60000]\n",
      "loss: 0.702618  [12864/60000]\n",
      "loss: 0.993976  [19264/60000]\n",
      "loss: 0.875775  [25664/60000]\n",
      "loss: 0.816994  [32064/60000]\n",
      "loss: 0.793461  [38464/60000]\n",
      "loss: 0.855158  [44864/60000]\n",
      "loss: 0.813358  [51264/60000]\n",
      "loss: 0.761313  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.814895 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.675989  [   64/60000]\n",
      "loss: 0.704629  [ 6464/60000]\n",
      "loss: 0.637081  [12864/60000]\n",
      "loss: 0.719171  [19264/60000]\n",
      "loss: 0.798009  [25664/60000]\n",
      "loss: 0.975916  [32064/60000]\n",
      "loss: 0.630513  [38464/60000]\n",
      "loss: 0.705353  [44864/60000]\n",
      "loss: 0.691880  [51264/60000]\n",
      "loss: 0.726700  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.786034 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.665800  [   64/60000]\n",
      "loss: 0.706287  [ 6464/60000]\n",
      "loss: 0.685147  [12864/60000]\n",
      "loss: 0.855696  [19264/60000]\n",
      "loss: 0.639109  [25664/60000]\n",
      "loss: 0.728808  [32064/60000]\n",
      "loss: 0.782853  [38464/60000]\n",
      "loss: 0.790812  [44864/60000]\n",
      "loss: 0.765640  [51264/60000]\n",
      "loss: 0.702284  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.760154 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.748533  [   64/60000]\n",
      "loss: 0.742346  [ 6464/60000]\n",
      "loss: 0.733712  [12864/60000]\n",
      "loss: 0.665728  [19264/60000]\n",
      "loss: 0.528315  [25664/60000]\n",
      "loss: 0.714138  [32064/60000]\n",
      "loss: 0.685374  [38464/60000]\n",
      "loss: 0.645557  [44864/60000]\n",
      "loss: 0.748687  [51264/60000]\n",
      "loss: 0.758236  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.736904 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.653436  [   64/60000]\n",
      "loss: 0.575294  [ 6464/60000]\n",
      "loss: 0.655169  [12864/60000]\n",
      "loss: 0.673202  [19264/60000]\n",
      "loss: 0.850770  [25664/60000]\n",
      "loss: 0.724190  [32064/60000]\n",
      "loss: 0.758146  [38464/60000]\n",
      "loss: 0.792586  [44864/60000]\n",
      "loss: 0.633833  [51264/60000]\n",
      "loss: 0.594607  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.717138 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.539319  [   64/60000]\n",
      "loss: 0.966229  [ 6464/60000]\n",
      "loss: 0.608296  [12864/60000]\n",
      "loss: 0.762840  [19264/60000]\n",
      "loss: 0.677684  [25664/60000]\n",
      "loss: 0.648342  [32064/60000]\n",
      "loss: 0.733118  [38464/60000]\n",
      "loss: 0.851328  [44864/60000]\n",
      "loss: 0.590934  [51264/60000]\n",
      "loss: 0.616433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.700100 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.601895  [   64/60000]\n",
      "loss: 0.596038  [ 6464/60000]\n",
      "loss: 0.729730  [12864/60000]\n",
      "loss: 0.657225  [19264/60000]\n",
      "loss: 0.698578  [25664/60000]\n",
      "loss: 0.757358  [32064/60000]\n",
      "loss: 0.521421  [38464/60000]\n",
      "loss: 0.573224  [44864/60000]\n",
      "loss: 0.687291  [51264/60000]\n",
      "loss: 0.567108  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.682107 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.671429  [   64/60000]\n",
      "loss: 0.702745  [ 6464/60000]\n",
      "loss: 0.645344  [12864/60000]\n",
      "loss: 0.789184  [19264/60000]\n",
      "loss: 0.617742  [25664/60000]\n",
      "loss: 0.748665  [32064/60000]\n",
      "loss: 0.654593  [38464/60000]\n",
      "loss: 0.607346  [44864/60000]\n",
      "loss: 0.624909  [51264/60000]\n",
      "loss: 0.671905  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.668009 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.556555  [   64/60000]\n",
      "loss: 0.556110  [ 6464/60000]\n",
      "loss: 0.610952  [12864/60000]\n",
      "loss: 0.626336  [19264/60000]\n",
      "loss: 0.627527  [25664/60000]\n",
      "loss: 0.687215  [32064/60000]\n",
      "loss: 0.716928  [38464/60000]\n",
      "loss: 0.504487  [44864/60000]\n",
      "loss: 0.690785  [51264/60000]\n",
      "loss: 0.746439  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.655658 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.746346  [   64/60000]\n",
      "loss: 0.707538  [ 6464/60000]\n",
      "loss: 0.693359  [12864/60000]\n",
      "loss: 0.457454  [19264/60000]\n",
      "loss: 0.835646  [25664/60000]\n",
      "loss: 0.689266  [32064/60000]\n",
      "loss: 0.610538  [38464/60000]\n",
      "loss: 0.596975  [44864/60000]\n",
      "loss: 0.632577  [51264/60000]\n",
      "loss: 0.666144  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.642791 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.480773  [   64/60000]\n",
      "loss: 0.577765  [ 6464/60000]\n",
      "loss: 0.681076  [12864/60000]\n",
      "loss: 0.535108  [19264/60000]\n",
      "loss: 0.586190  [25664/60000]\n",
      "loss: 0.644002  [32064/60000]\n",
      "loss: 0.761867  [38464/60000]\n",
      "loss: 0.565674  [44864/60000]\n",
      "loss: 0.519498  [51264/60000]\n",
      "loss: 0.518124  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.632352 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.520060  [   64/60000]\n",
      "loss: 0.533828  [ 6464/60000]\n",
      "loss: 0.589199  [12864/60000]\n",
      "loss: 0.562327  [19264/60000]\n",
      "loss: 0.458661  [25664/60000]\n",
      "loss: 0.554966  [32064/60000]\n",
      "loss: 0.788079  [38464/60000]\n",
      "loss: 0.672788  [44864/60000]\n",
      "loss: 0.579647  [51264/60000]\n",
      "loss: 0.563253  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.621607 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.448332  [   64/60000]\n",
      "loss: 0.551716  [ 6464/60000]\n",
      "loss: 0.614413  [12864/60000]\n",
      "loss: 0.558245  [19264/60000]\n",
      "loss: 0.645195  [25664/60000]\n",
      "loss: 0.771885  [32064/60000]\n",
      "loss: 0.607120  [38464/60000]\n",
      "loss: 0.524268  [44864/60000]\n",
      "loss: 0.596054  [51264/60000]\n",
      "loss: 0.748913  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.611009 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.490927  [   64/60000]\n",
      "loss: 0.613655  [ 6464/60000]\n",
      "loss: 0.449579  [12864/60000]\n",
      "loss: 0.586218  [19264/60000]\n",
      "loss: 0.732266  [25664/60000]\n",
      "loss: 0.485798  [32064/60000]\n",
      "loss: 0.683085  [38464/60000]\n",
      "loss: 0.383384  [44864/60000]\n",
      "loss: 0.589829  [51264/60000]\n",
      "loss: 0.629494  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.603078 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.640699  [   64/60000]\n",
      "loss: 0.347966  [ 6464/60000]\n",
      "loss: 0.412703  [12864/60000]\n",
      "loss: 0.648332  [19264/60000]\n",
      "loss: 0.471716  [25664/60000]\n",
      "loss: 0.640950  [32064/60000]\n",
      "loss: 0.598569  [38464/60000]\n",
      "loss: 0.659949  [44864/60000]\n",
      "loss: 0.505826  [51264/60000]\n",
      "loss: 0.494875  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.593199 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.524981  [   64/60000]\n",
      "loss: 0.577592  [ 6464/60000]\n",
      "loss: 0.744884  [12864/60000]\n",
      "loss: 0.595168  [19264/60000]\n",
      "loss: 0.462114  [25664/60000]\n",
      "loss: 0.699556  [32064/60000]\n",
      "loss: 0.472172  [38464/60000]\n",
      "loss: 0.559291  [44864/60000]\n",
      "loss: 0.912936  [51264/60000]\n",
      "loss: 0.553893  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.586477 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.707192  [   64/60000]\n",
      "loss: 0.558381  [ 6464/60000]\n",
      "loss: 0.558552  [12864/60000]\n",
      "loss: 0.603539  [19264/60000]\n",
      "loss: 0.790191  [25664/60000]\n",
      "loss: 0.657007  [32064/60000]\n",
      "loss: 0.621974  [38464/60000]\n",
      "loss: 0.623831  [44864/60000]\n",
      "loss: 0.481800  [51264/60000]\n",
      "loss: 0.508561  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.580502 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.598804  [   64/60000]\n",
      "loss: 0.602152  [ 6464/60000]\n",
      "loss: 0.625775  [12864/60000]\n",
      "loss: 0.344036  [19264/60000]\n",
      "loss: 0.612795  [25664/60000]\n",
      "loss: 0.472679  [32064/60000]\n",
      "loss: 0.404877  [38464/60000]\n",
      "loss: 0.643475  [44864/60000]\n",
      "loss: 0.469605  [51264/60000]\n",
      "loss: 0.400541  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.575454 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.766382  [   64/60000]\n",
      "loss: 0.421352  [ 6464/60000]\n",
      "loss: 0.588120  [12864/60000]\n",
      "loss: 0.598888  [19264/60000]\n",
      "loss: 0.528968  [25664/60000]\n",
      "loss: 0.519113  [32064/60000]\n",
      "loss: 0.603131  [38464/60000]\n",
      "loss: 0.512276  [44864/60000]\n",
      "loss: 0.483785  [51264/60000]\n",
      "loss: 0.625190  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.567189 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.455603  [   64/60000]\n",
      "loss: 0.477301  [ 6464/60000]\n",
      "loss: 0.696649  [12864/60000]\n",
      "loss: 0.441572  [19264/60000]\n",
      "loss: 0.466473  [25664/60000]\n",
      "loss: 0.607758  [32064/60000]\n",
      "loss: 0.472196  [38464/60000]\n",
      "loss: 0.524018  [44864/60000]\n",
      "loss: 0.424359  [51264/60000]\n",
      "loss: 0.512065  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.559939 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.661780  [   64/60000]\n",
      "loss: 0.373927  [ 6464/60000]\n",
      "loss: 0.630993  [12864/60000]\n",
      "loss: 0.584028  [19264/60000]\n",
      "loss: 0.579577  [25664/60000]\n",
      "loss: 0.627773  [32064/60000]\n",
      "loss: 0.371857  [38464/60000]\n",
      "loss: 0.536624  [44864/60000]\n",
      "loss: 0.503832  [51264/60000]\n",
      "loss: 0.532931  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.554433 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.494440  [   64/60000]\n",
      "loss: 0.514563  [ 6464/60000]\n",
      "loss: 0.423100  [12864/60000]\n",
      "loss: 0.542459  [19264/60000]\n",
      "loss: 0.576578  [25664/60000]\n",
      "loss: 0.724119  [32064/60000]\n",
      "loss: 0.699753  [38464/60000]\n",
      "loss: 0.670469  [44864/60000]\n",
      "loss: 0.426024  [51264/60000]\n",
      "loss: 0.558713  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.551019 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803674ac-5b0e-4c5a-bfb0-2840aadb65bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298174  [   64/60000]\n",
      "loss: 0.619142  [ 6464/60000]\n",
      "loss: 0.540211  [12864/60000]\n",
      "loss: 0.609923  [19264/60000]\n",
      "loss: 0.470536  [25664/60000]\n",
      "loss: 0.385651  [32064/60000]\n",
      "loss: 0.318150  [38464/60000]\n",
      "loss: 0.394950  [44864/60000]\n",
      "loss: 0.364814  [51264/60000]\n",
      "loss: 0.432497  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.413418 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.537303  [   64/60000]\n",
      "loss: 0.308946  [ 6464/60000]\n",
      "loss: 0.445579  [12864/60000]\n",
      "loss: 0.252664  [19264/60000]\n",
      "loss: 0.327632  [25664/60000]\n",
      "loss: 0.418841  [32064/60000]\n",
      "loss: 0.348536  [38464/60000]\n",
      "loss: 0.410786  [44864/60000]\n",
      "loss: 0.425308  [51264/60000]\n",
      "loss: 0.312756  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.385581 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.306918  [   64/60000]\n",
      "loss: 0.386514  [ 6464/60000]\n",
      "loss: 0.190221  [12864/60000]\n",
      "loss: 0.375508  [19264/60000]\n",
      "loss: 0.243451  [25664/60000]\n",
      "loss: 0.466014  [32064/60000]\n",
      "loss: 0.222843  [38464/60000]\n",
      "loss: 0.330216  [44864/60000]\n",
      "loss: 0.397688  [51264/60000]\n",
      "loss: 0.248436  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.349343 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.291924  [   64/60000]\n",
      "loss: 0.201293  [ 6464/60000]\n",
      "loss: 0.201255  [12864/60000]\n",
      "loss: 0.201303  [19264/60000]\n",
      "loss: 0.251977  [25664/60000]\n",
      "loss: 0.321313  [32064/60000]\n",
      "loss: 0.257111  [38464/60000]\n",
      "loss: 0.212669  [44864/60000]\n",
      "loss: 0.351336  [51264/60000]\n",
      "loss: 0.275813  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.348982 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.195613  [   64/60000]\n",
      "loss: 0.469029  [ 6464/60000]\n",
      "loss: 0.227122  [12864/60000]\n",
      "loss: 0.301837  [19264/60000]\n",
      "loss: 0.330372  [25664/60000]\n",
      "loss: 0.268642  [32064/60000]\n",
      "loss: 0.238839  [38464/60000]\n",
      "loss: 0.322836  [44864/60000]\n",
      "loss: 0.259217  [51264/60000]\n",
      "loss: 0.326837  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340075 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.517682  [   64/60000]\n",
      "loss: 0.300984  [ 6464/60000]\n",
      "loss: 0.116087  [12864/60000]\n",
      "loss: 0.272526  [19264/60000]\n",
      "loss: 0.198980  [25664/60000]\n",
      "loss: 0.212627  [32064/60000]\n",
      "loss: 0.264599  [38464/60000]\n",
      "loss: 0.437536  [44864/60000]\n",
      "loss: 0.259023  [51264/60000]\n",
      "loss: 0.379543  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.321360 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.271391  [   64/60000]\n",
      "loss: 0.355881  [ 6464/60000]\n",
      "loss: 0.207601  [12864/60000]\n",
      "loss: 0.342975  [19264/60000]\n",
      "loss: 0.275642  [25664/60000]\n",
      "loss: 0.160941  [32064/60000]\n",
      "loss: 0.151773  [38464/60000]\n",
      "loss: 0.218775  [44864/60000]\n",
      "loss: 0.210036  [51264/60000]\n",
      "loss: 0.257328  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.321290 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.169941  [   64/60000]\n",
      "loss: 0.190921  [ 6464/60000]\n",
      "loss: 0.129346  [12864/60000]\n",
      "loss: 0.084811  [19264/60000]\n",
      "loss: 0.162086  [25664/60000]\n",
      "loss: 0.201642  [32064/60000]\n",
      "loss: 0.223496  [38464/60000]\n",
      "loss: 0.236106  [44864/60000]\n",
      "loss: 0.232058  [51264/60000]\n",
      "loss: 0.309119  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.350920 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.156741  [   64/60000]\n",
      "loss: 0.161369  [ 6464/60000]\n",
      "loss: 0.204362  [12864/60000]\n",
      "loss: 0.203328  [19264/60000]\n",
      "loss: 0.267799  [25664/60000]\n",
      "loss: 0.469434  [32064/60000]\n",
      "loss: 0.131673  [38464/60000]\n",
      "loss: 0.196296  [44864/60000]\n",
      "loss: 0.306555  [51264/60000]\n",
      "loss: 0.243831  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.364520 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.310845  [   64/60000]\n",
      "loss: 0.261413  [ 6464/60000]\n",
      "loss: 0.362166  [12864/60000]\n",
      "loss: 0.157002  [19264/60000]\n",
      "loss: 0.292044  [25664/60000]\n",
      "loss: 0.399451  [32064/60000]\n",
      "loss: 0.253250  [38464/60000]\n",
      "loss: 0.175440  [44864/60000]\n",
      "loss: 0.397140  [51264/60000]\n",
      "loss: 0.211738  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.340545 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbdbbc44-3873-486d-b5d6-9159b46a7b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300718  [   64/60000]\n",
      "loss: 0.663986  [ 6464/60000]\n",
      "loss: 0.451158  [12864/60000]\n",
      "loss: 0.873041  [19264/60000]\n",
      "loss: 0.497125  [25664/60000]\n",
      "loss: 0.376960  [32064/60000]\n",
      "loss: 0.533196  [38464/60000]\n",
      "loss: 0.387961  [44864/60000]\n",
      "loss: 0.433978  [51264/60000]\n",
      "loss: 0.395736  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.417189 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.510163  [   64/60000]\n",
      "loss: 0.413671  [ 6464/60000]\n",
      "loss: 0.314601  [12864/60000]\n",
      "loss: 0.241392  [19264/60000]\n",
      "loss: 0.241422  [25664/60000]\n",
      "loss: 0.377913  [32064/60000]\n",
      "loss: 0.367820  [38464/60000]\n",
      "loss: 0.497404  [44864/60000]\n",
      "loss: 0.179050  [51264/60000]\n",
      "loss: 0.303107  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.364598 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.200794  [   64/60000]\n",
      "loss: 0.229420  [ 6464/60000]\n",
      "loss: 0.339456  [12864/60000]\n",
      "loss: 0.375332  [19264/60000]\n",
      "loss: 0.269926  [25664/60000]\n",
      "loss: 0.472511  [32064/60000]\n",
      "loss: 0.541384  [38464/60000]\n",
      "loss: 0.203669  [44864/60000]\n",
      "loss: 0.247733  [51264/60000]\n",
      "loss: 0.243602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.350209 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.416116  [   64/60000]\n",
      "loss: 0.250755  [ 6464/60000]\n",
      "loss: 0.244314  [12864/60000]\n",
      "loss: 0.232575  [19264/60000]\n",
      "loss: 0.538332  [25664/60000]\n",
      "loss: 0.213776  [32064/60000]\n",
      "loss: 0.354046  [38464/60000]\n",
      "loss: 0.345012  [44864/60000]\n",
      "loss: 0.279436  [51264/60000]\n",
      "loss: 0.216705  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.344372 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.489912  [   64/60000]\n",
      "loss: 0.227376  [ 6464/60000]\n",
      "loss: 0.305109  [12864/60000]\n",
      "loss: 0.313847  [19264/60000]\n",
      "loss: 0.245711  [25664/60000]\n",
      "loss: 0.114988  [32064/60000]\n",
      "loss: 0.209515  [38464/60000]\n",
      "loss: 0.218842  [44864/60000]\n",
      "loss: 0.270523  [51264/60000]\n",
      "loss: 0.315592  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.339269 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.211023  [   64/60000]\n",
      "loss: 0.347702  [ 6464/60000]\n",
      "loss: 0.387959  [12864/60000]\n",
      "loss: 0.272934  [19264/60000]\n",
      "loss: 0.277184  [25664/60000]\n",
      "loss: 0.216853  [32064/60000]\n",
      "loss: 0.171118  [38464/60000]\n",
      "loss: 0.209232  [44864/60000]\n",
      "loss: 0.282585  [51264/60000]\n",
      "loss: 0.120754  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.325128 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.123034  [   64/60000]\n",
      "loss: 0.340621  [ 6464/60000]\n",
      "loss: 0.527581  [12864/60000]\n",
      "loss: 0.192273  [19264/60000]\n",
      "loss: 0.093155  [25664/60000]\n",
      "loss: 0.402465  [32064/60000]\n",
      "loss: 0.269881  [38464/60000]\n",
      "loss: 0.210618  [44864/60000]\n",
      "loss: 0.202098  [51264/60000]\n",
      "loss: 0.366456  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.357926 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.226933  [   64/60000]\n",
      "loss: 0.206605  [ 6464/60000]\n",
      "loss: 0.318329  [12864/60000]\n",
      "loss: 0.282077  [19264/60000]\n",
      "loss: 0.250250  [25664/60000]\n",
      "loss: 0.255833  [32064/60000]\n",
      "loss: 0.235231  [38464/60000]\n",
      "loss: 0.156610  [44864/60000]\n",
      "loss: 0.285993  [51264/60000]\n",
      "loss: 0.209879  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.340964 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.335439  [   64/60000]\n",
      "loss: 0.228148  [ 6464/60000]\n",
      "loss: 0.176920  [12864/60000]\n",
      "loss: 0.337037  [19264/60000]\n",
      "loss: 0.163752  [25664/60000]\n",
      "loss: 0.180509  [32064/60000]\n",
      "loss: 0.128342  [38464/60000]\n",
      "loss: 0.302091  [44864/60000]\n",
      "loss: 0.204444  [51264/60000]\n",
      "loss: 0.284672  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.324055 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.494894  [   64/60000]\n",
      "loss: 0.174869  [ 6464/60000]\n",
      "loss: 0.251703  [12864/60000]\n",
      "loss: 0.250281  [19264/60000]\n",
      "loss: 0.293308  [25664/60000]\n",
      "loss: 0.193676  [32064/60000]\n",
      "loss: 0.143787  [38464/60000]\n",
      "loss: 0.413674  [44864/60000]\n",
      "loss: 0.127390  [51264/60000]\n",
      "loss: 0.437950  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.346600 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.226656  [   64/60000]\n",
      "loss: 0.098054  [ 6464/60000]\n",
      "loss: 0.182537  [12864/60000]\n",
      "loss: 0.194769  [19264/60000]\n",
      "loss: 0.375592  [25664/60000]\n",
      "loss: 0.253946  [32064/60000]\n",
      "loss: 0.116815  [38464/60000]\n",
      "loss: 0.198424  [44864/60000]\n",
      "loss: 0.198239  [51264/60000]\n",
      "loss: 0.255615  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.338917 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.141756  [   64/60000]\n",
      "loss: 0.188561  [ 6464/60000]\n",
      "loss: 0.173792  [12864/60000]\n",
      "loss: 0.228386  [19264/60000]\n",
      "loss: 0.120398  [25664/60000]\n",
      "loss: 0.206739  [32064/60000]\n",
      "loss: 0.386057  [38464/60000]\n",
      "loss: 0.352606  [44864/60000]\n",
      "loss: 0.184695  [51264/60000]\n",
      "loss: 0.286507  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.338809 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.158309  [   64/60000]\n",
      "loss: 0.311323  [ 6464/60000]\n",
      "loss: 0.121936  [12864/60000]\n",
      "loss: 0.149228  [19264/60000]\n",
      "loss: 0.270695  [25664/60000]\n",
      "loss: 0.111245  [32064/60000]\n",
      "loss: 0.190253  [38464/60000]\n",
      "loss: 0.232866  [44864/60000]\n",
      "loss: 0.201574  [51264/60000]\n",
      "loss: 0.187233  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.370854 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.174474  [   64/60000]\n",
      "loss: 0.179079  [ 6464/60000]\n",
      "loss: 0.205220  [12864/60000]\n",
      "loss: 0.225674  [19264/60000]\n",
      "loss: 0.151526  [25664/60000]\n",
      "loss: 0.201203  [32064/60000]\n",
      "loss: 0.093515  [38464/60000]\n",
      "loss: 0.102753  [44864/60000]\n",
      "loss: 0.170493  [51264/60000]\n",
      "loss: 0.192159  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.338253 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.120537  [   64/60000]\n",
      "loss: 0.214109  [ 6464/60000]\n",
      "loss: 0.255445  [12864/60000]\n",
      "loss: 0.071878  [19264/60000]\n",
      "loss: 0.086235  [25664/60000]\n",
      "loss: 0.254771  [32064/60000]\n",
      "loss: 0.142937  [38464/60000]\n",
      "loss: 0.212960  [44864/60000]\n",
      "loss: 0.082921  [51264/60000]\n",
      "loss: 0.217458  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.344018 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.182046  [   64/60000]\n",
      "loss: 0.216998  [ 6464/60000]\n",
      "loss: 0.148974  [12864/60000]\n",
      "loss: 0.102810  [19264/60000]\n",
      "loss: 0.128453  [25664/60000]\n",
      "loss: 0.245324  [32064/60000]\n",
      "loss: 0.134896  [38464/60000]\n",
      "loss: 0.143820  [44864/60000]\n",
      "loss: 0.266955  [51264/60000]\n",
      "loss: 0.085868  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.372214 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.141013  [   64/60000]\n",
      "loss: 0.157764  [ 6464/60000]\n",
      "loss: 0.151309  [12864/60000]\n",
      "loss: 0.422241  [19264/60000]\n",
      "loss: 0.188907  [25664/60000]\n",
      "loss: 0.208574  [32064/60000]\n",
      "loss: 0.112722  [38464/60000]\n",
      "loss: 0.158089  [44864/60000]\n",
      "loss: 0.172066  [51264/60000]\n",
      "loss: 0.101709  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.373765 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.065631  [   64/60000]\n",
      "loss: 0.227548  [ 6464/60000]\n",
      "loss: 0.113502  [12864/60000]\n",
      "loss: 0.080189  [19264/60000]\n",
      "loss: 0.173580  [25664/60000]\n",
      "loss: 0.117771  [32064/60000]\n",
      "loss: 0.108052  [38464/60000]\n",
      "loss: 0.357847  [44864/60000]\n",
      "loss: 0.147077  [51264/60000]\n",
      "loss: 0.244525  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.367156 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.071355  [   64/60000]\n",
      "loss: 0.174321  [ 6464/60000]\n",
      "loss: 0.100827  [12864/60000]\n",
      "loss: 0.164176  [19264/60000]\n",
      "loss: 0.128595  [25664/60000]\n",
      "loss: 0.229232  [32064/60000]\n",
      "loss: 0.140283  [38464/60000]\n",
      "loss: 0.186343  [44864/60000]\n",
      "loss: 0.162090  [51264/60000]\n",
      "loss: 0.168054  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.403841 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.073703  [   64/60000]\n",
      "loss: 0.107638  [ 6464/60000]\n",
      "loss: 0.220982  [12864/60000]\n",
      "loss: 0.229278  [19264/60000]\n",
      "loss: 0.191238  [25664/60000]\n",
      "loss: 0.122176  [32064/60000]\n",
      "loss: 0.128372  [38464/60000]\n",
      "loss: 0.179102  [44864/60000]\n",
      "loss: 0.137258  [51264/60000]\n",
      "loss: 0.096824  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.384387 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f114b299-805b-4ddb-a380-15335ae253db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '__local/models/1.1-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e044e51-3fa1-4bac-945b-3bbaf868a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('__local/models/1.1-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62443b8-ffda-4ab3-9645-fa460deceaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
